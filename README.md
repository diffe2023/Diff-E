# Diff-E
Decoding imagined speech from EEG signals is an important area of research that has the potential to revolutionize communication through brain signals. However, due to the high-dimensional nature of EEG data and the low signal-to-noise ratio, decoding imagined speech from EEG signals is a challenging task. In recent years, the use of denoising diffusion probabilistic models (DDPMs) has emerged as a promising approach for learning representations in numerous domains. In this study, we propose a novel method for decoding imagined speech from EEG signals using DDPMs and a conditional autoencoder, which we call Diff-E. Results show that Diff-E significantly improves the decoding accuracy of imagined speech compared to traditional machine-learning techniques and baseline models. Findings suggest that DDPMs are an effective means of decoding EEG signals, and it has promising implications for the development of brain-computer interfaces that enable communication through imagined speech.
